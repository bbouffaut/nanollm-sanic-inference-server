{
    "llama-server-gemma2": {
        "type": "CHAT_COMPLETION",
        "name": "LlamaCppModel",
        "params": {
            "model_path": "/data/models/huggingface/gemma-2-2b-it-Q3_K_L.gguf",
            "gpu": "True"
        }
    },
    "llama-server-gemma3": {
        "type": "CHAT_COMPLETION",
        "name": "LlamaCppModel",
        "params": {
            "model_path": "/data/models/huggingface/gemma-3-4b-it-Q4_K_M.gguf",
            "gpu": "True"
        }
    },
    "nanollm-server-gemma2": {
        "type": "CHAT_COMPLETION",
        "name": "NanoLlmModel",
        "params": {
            "model_path": "/data/models/huggingface/gemma-2b-it",
            "gpu": "True"
        }
    },
    "nanollm-server-gemma2-hf": {
        "type": "CHAT_COMPLETION",
        "name": "NanoLlmModel",
        "params": {
            "model_path": "google/gemma-2b-it",
            "api": "hf",
            "quantization": "/data/models/huggingface/hub/models--mlc-ai--gemma-2-2b-it-q4f16_1-MLC/snapshots/4f3984195840df4234e4e34c7904e63d40154190",
            "gpu": "True"
        }
    },
    "echo-server-with-tokenizer": {
        "type": "NONE",
        "name": "EchoModelWithTokenizer",
        "params": {}
    },
    "echo-server": {
        "type": "NONE",
        "name": "EchoModel",
        "params": {}
    },
    "mock-server": {
        "type": "NONE",
        "name": "MockModel",
        "params": {}
    }
}
